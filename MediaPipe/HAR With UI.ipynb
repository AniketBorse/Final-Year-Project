{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b63ab6227b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmp_drawing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/DELL/Downloads/HAR_Dataset-20230601T155736Z-001/HAR_Dataset/har_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpose_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatic_image_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_detection_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_complexity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m                 )\n\u001b[0;32m    114\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 raise TypeError(\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[1;34mf\"{k} is not a valid argument, kwargs should be empty \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[1;34m\" for `optimizer_experimental.Optimizer`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`."
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "model = load_model(\"C:/Users/DELL/Downloads/HAR_Dataset-20230601T155736Z-001/HAR_Dataset/har_model.h5\")\n",
    "\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "\n",
    "def detectPose(image, pose):\n",
    "    # Create a copy of the input image.\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(imageRGB)\n",
    "\n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Initialize a list to store the detected landmarks.\n",
    "    landmarks = []\n",
    "\n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        # Draw Pose landmarks on the output image.\n",
    "#         mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
    "#                                   connections=mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Iterate over the detected landmarks.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            # Append the landmark into the list.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                              (landmark.z * width)))\n",
    "\n",
    "    return output_image, landmarks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    # Get the required landmarks coordinates.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "\n",
    "    # Check if the angle is less than zero.\n",
    "    if angle < 0:\n",
    "        # Add 360 to the found angle.\n",
    "        angle += 360\n",
    "\n",
    "    # Return the calculated angle.\n",
    "    return angle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classifyPose(landmarks, output_image):\n",
    "    # Initialize the label of the pose. It is not known at this stage.\n",
    "    label = 'Unknown Pose'\n",
    "\n",
    "    # Specify the color (Red) with which the label will be written on the image.\n",
    "    color = (0, 0, 255)\n",
    "\n",
    "    # Calculate the required angles.\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Get the angle between the left shoulder, elbow and wrist points.\n",
    "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "\n",
    "    # Get the angle between the right shoulder, elbow and wrist points.\n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "\n",
    "    # Get the angle between the left elbow, shoulder and hip points.\n",
    "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "\n",
    "    # Get the angle between the right hip, shoulder and elbow points.\n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "    # Get the angle between the left hip, knee and ankle points.\n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right hip, knee and ankle points\n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right shoulder, knee and hip points\n",
    "    right_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
    "\n",
    "    # Get the angle between the left shoulder, knee and hip points\n",
    "    left_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    angles = [round(left_elbow_angle, 2) / 360, round(right_elbow_angle, 2) / 360 ,\n",
    "              round(left_shoulder_angle, 2) / 360, round(right_shoulder_angle, 2) / 360, \n",
    "              round(left_hip_angle, 2) / 360, round(right_hip_angle, 2) / 360, round(left_knee_angle, 2) / 360, \n",
    "              round(right_knee_angle, 2) / 360]\n",
    "    feature_vector = np.array(angles).reshape(-1, 8)\n",
    "    prediction = model.predict(feature_vector)\n",
    "    \n",
    "    probable_act = np.argmax(prediction[0])\n",
    "    \n",
    "    if probable_act == 0:\n",
    "           label = 'Sitting'\n",
    "           \n",
    "    elif probable_act == 1:\n",
    "           label = 'Standing'\n",
    "           \n",
    "    elif probable_act == 2:\n",
    "           label = 'Walking'\n",
    "           \n",
    "    elif probable_act == 3:\n",
    "           label = 'Waving Hands'\n",
    "           \n",
    "    elif probable_act  == 4:\n",
    "           label = 'Yoga'\n",
    "           \n",
    "    elif probable_act == 5:\n",
    "           label = 'Squats'\n",
    "             \n",
    "    \n",
    "\n",
    "    # Check if the pose is classified successfully\n",
    "    if label != 'Unknown Pose':\n",
    "        # Update the color (to green) with which the label will be written on the image.\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "    # Write the label on the output image.\n",
    "    cv2.putText(output_image, label, (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "    \n",
    "    # print the pose details\n",
    "    # print(f\"{round(left_elbow_angle, 2)},{round(right_elbow_angle, 2)},{round(left_shoulder_angle, 2)},{round(right_shoulder_angle, 2)},{round(left_hip_angle, 2)},{round(right_hip_angle, 2)},{round(left_knee_angle, 2)},{round(right_knee_angle, 2)},Squats\")\n",
    "\n",
    "    return output_image, f'{label}'\n",
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        self.video_path = None\n",
    "        self.cap = None\n",
    "        self.playing = False\n",
    "\n",
    "        master.configure(background=\"skyblue\")\n",
    "\n",
    "        window_width = 900\n",
    "        window_height = 600\n",
    "\n",
    "        # get the screen width and height\n",
    "        screen_width = master.winfo_screenwidth()\n",
    "        screen_height = master.winfo_screenheight()\n",
    "\n",
    "        # calculate the x and y coordinates of the top-left corner of the window\n",
    "        x = (screen_width // 2) - (window_width // 2)\n",
    "        y = (screen_height // 2) - (window_height // 2)\n",
    "\n",
    "        root.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "\n",
    "        # create UI elements\n",
    "        self.label = tk.Label(master, text=\"No video selected\", font=(\"Arial\", 20), bg=\"skyblue\")\n",
    "        self.label.pack(pady=10)\n",
    "\n",
    "        self.button_select = tk.Button(master, text=\"Select video\", command=self.select_video, font=(\"Arial\", 20),\n",
    "                                       bg=\"yellow\")\n",
    "        self.button_select.pack()\n",
    "\n",
    "        self.button_play = tk.Button(master, text=\"Play\", state=\"disabled\", command=self.play_video, font=(\"Arial\", 20),\n",
    "                                     bg=\"white\")\n",
    "        self.button_play.pack(pady=10)\n",
    "\n",
    "        self.button_select = tk.Button(master, text=\"Use Camera\", command=self.webcam, font=(\"Arial\", 20),\n",
    "                                       bg=\"yellow\")\n",
    "        self.button_select.pack()\n",
    "        \n",
    "        footer_frame = tk.Frame(self.master, bg=\"black\")\n",
    "        footer_frame.pack(side=\"bottom\", fill=\"x\")\n",
    "\n",
    "        footer_label = tk.Label(footer_frame, text=\"Developed By : Shivam Nikam, Mohit Wadekar, Aniket Borse, Chinmay Mahajan\", font=(\"Arial\", 12), bg=\"black\", fg=\"white\")\n",
    "        footer_label.pack(pady=5)\n",
    "\n",
    "    def select_video(self):\n",
    "        self.video_path = filedialog.askopenfilename()\n",
    "        self.label.config(text=self.video_path)\n",
    "        self.cap = cv2.VideoCapture(self.video_path)\n",
    "        self.button_play.config(state=\"normal\")\n",
    "\n",
    "    def select_cam(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "    def play_video(self):\n",
    "        if not self.playing:\n",
    "            self.playing = True\n",
    "            while True:\n",
    "                \n",
    "                ok, frame = self.cap.read()\n",
    "\n",
    "                if not ok:\n",
    "                    break\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "                frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "                frame, landmarks = detectPose(frame, pose_video)\n",
    "\n",
    "                if landmarks:\n",
    "                    \n",
    "                    frame, _ = classifyPose(landmarks, frame)\n",
    "\n",
    "                cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    self.label.configure(text=\"No Video Selected\")\n",
    "                    break\n",
    "                    \n",
    "            cv2.destroyAllWindows()\n",
    "            self.cap.release()\n",
    "            self.playing = False\n",
    "            self.button_play.config(text=\"Play\")\n",
    "        else:\n",
    "            self.playing = False\n",
    "\n",
    "    def webcam(self):\n",
    "        self.select_cam()\n",
    "        if not self.playing:\n",
    "            self.playing = True\n",
    "            while True:\n",
    "                ok, frame = self.cap.read()\n",
    "                \n",
    "\n",
    "                if not ok:\n",
    "                    break\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "                frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "                frame, landmarks = detectPose(frame, pose_video)\n",
    "\n",
    "                if landmarks:\n",
    "                    frame, _ = classifyPose(landmarks, frame)\n",
    "\n",
    "                cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    self.label.configure(text=\"No Video Selected\")\n",
    "                    break\n",
    "            \n",
    "            cv2.destroyAllWindows()\n",
    "            self.cap.release()\n",
    "            \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Human Activity Recognition App\")\n",
    "    player = VideoPlayer(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
