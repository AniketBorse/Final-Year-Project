{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3d90cd776239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmp_drawing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/DELL/Downloads/HAR_Dataset-20230601T155736Z-001/HAR_Dataset/har_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetectPose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m                 )\n\u001b[0;32m    114\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 raise TypeError(\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[1;34mf\"{k} is not a valid argument, kwargs should be empty \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[1;34m\" for `optimizer_experimental.Optimizer`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "model = load_model(\"C:/Users/DELL/Downloads/HAR_Dataset-20230601T155736Z-001/HAR_Dataset/har_model.h5\")\n",
    "\n",
    "def detectPose(image, pose):\n",
    "    # Create a copy of the input image.\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(imageRGB)\n",
    "\n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Initialize a list to store the detected landmarks.\n",
    "    landmarks = []\n",
    "\n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        # Draw Pose landmarks on the output image.\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
    "                                  connections=mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Iterate over the detected landmarks.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            # Append the landmark into the list.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                              (landmark.z * width)))\n",
    "\n",
    "    return output_image, landmarks\n",
    "\n",
    "\n",
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    # Get the required landmarks coordinates.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "\n",
    "    # Check if the angle is less than zero.\n",
    "    if angle < 0:\n",
    "        # Add 360 to the found angle.\n",
    "        angle += 360\n",
    "\n",
    "    # Return the calculated angle.\n",
    "    return angle\n",
    "\n",
    "\n",
    "def classifyPose(landmarks, output_image):\n",
    "    # Initialize the label of the pose. It is not known at this stage.\n",
    "    label = 'Unknown Pose'\n",
    "\n",
    "    # Specify the color (Red) with which the label will be written on the image.\n",
    "    color = (0, 0, 255)\n",
    "\n",
    "    # Calculate the required angles.\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Get the angle between the left shoulder, elbow and wrist points.\n",
    "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "\n",
    "    # Get the angle between the right shoulder, elbow and wrist points.\n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "\n",
    "    # Get the angle between the left elbow, shoulder and hip points.\n",
    "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "\n",
    "    # Get the angle between the right hip, shoulder and elbow points.\n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "    # Get the angle between the left hip, knee and ankle points.\n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right hip, knee and ankle points\n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right shoulder, knee and hip points\n",
    "    right_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
    "\n",
    "    # Get the angle between the left shoulder, knee and hip points\n",
    "    left_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    angles = [round(left_elbow_angle, 2) / 360, round(right_elbow_angle, 2) / 360 ,\n",
    "              round(left_shoulder_angle, 2) / 360, round(right_shoulder_angle, 2) / 360, \n",
    "              round(left_hip_angle, 2) / 360, round(right_hip_angle, 2) / 360, round(left_knee_angle, 2) / 360, \n",
    "              round(right_knee_angle, 2) / 360]\n",
    "    feature_vector = np.array(angles).reshape(-1, 8)\n",
    "    prediction = model.predict(feature_vector)\n",
    "    \n",
    "    probable_act = np.argmax(prediction[0])\n",
    "    \n",
    "    if probable_act == 0:\n",
    "           label = 'Sitting'\n",
    "           \n",
    "    elif probable_act== 1:\n",
    "           label = 'Standing'\n",
    "           \n",
    "    elif probable_act== 2:\n",
    "           label = 'Walking'\n",
    "           \n",
    "    elif probable_act== 3:\n",
    "           label = 'Waving Hands'\n",
    "           \n",
    "    elif probable_act  == 4:\n",
    "           label = 'Yoga'\n",
    "           \n",
    "    elif probable_act == 5:\n",
    "           label = 'Squats'\n",
    "             \n",
    "    \n",
    "\n",
    "    # Check if the pose is classified successfully\n",
    "    if label != 'Unknown Pose':\n",
    "        # Update the color (to green) with which the label will be written on the image.\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "    # Write the label on the output image.\n",
    "    cv2.putText(output_image, label, (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "    \n",
    "    # print the pose details\n",
    "    # print(f\"{round(left_elbow_angle, 2)},{round(right_elbow_angle, 2)},{round(left_shoulder_angle, 2)},{round(right_shoulder_angle, 2)},{round(left_hip_angle, 2)},{round(right_hip_angle, 2)},{round(left_knee_angle, 2)},{round(right_knee_angle, 2)},Squats\")\n",
    "\n",
    "    return output_image, f'{label}'\n",
    "\n",
    "\n",
    "# Setup Pose function for video.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "\n",
    "video_url = 'walking/9.mp4'\n",
    "\n",
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(video_url)\n",
    "\n",
    "# Initialize a resizable window.\n",
    "cv2.namedWindow('Pose Classification', cv2.WINDOW_NORMAL)\n",
    "\n",
    "\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "\n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "\n",
    "    # Check if frame is not read properly.\n",
    "    if not ok:\n",
    "        # Continue to the next iteration to read the next frame and ignore the empty camera frame.\n",
    "        break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #     Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    #     frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the width and height of the frame\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    # Resize the frame while keeping the aspect ratio.\n",
    "    frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "\n",
    "    # Perform Pose landmark detection.\n",
    "    frame, landmarks = detectPose(frame, pose_video)\n",
    "\n",
    "    # Check if the landmarks are detected.\n",
    "    if landmarks:\n",
    "        # Perform the Pose Classification.\n",
    "        frame, _ = classifyPose(landmarks, frame)\n",
    "\n",
    "    # Display the frame.\n",
    "    cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "    # Wait until a key is pressed.\n",
    "    # Retrieve the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Check if 'ESC' is pressed.\n",
    "    if k == 27:\n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close the windows.\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
