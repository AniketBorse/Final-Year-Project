{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f5dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "model = load_model('../HAR_Dataset/har_model.h5')\n",
    "\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "\n",
    "def detectPose(image, pose):\n",
    "    # Create a copy of the input image.\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(imageRGB)\n",
    "\n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Initialize a list to store the detected landmarks.\n",
    "    landmarks = []\n",
    "\n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        # Draw Pose landmarks on the output image.\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
    "                                  connections=mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Iterate over the detected landmarks.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            # Append the landmark into the list.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                              (landmark.z * width)))\n",
    "\n",
    "    return output_image, landmarks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    # Get the required landmarks coordinates.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "\n",
    "    # Check if the angle is less than zero.\n",
    "    if angle < 0:\n",
    "        # Add 360 to the found angle.\n",
    "        angle += 360\n",
    "\n",
    "    # Return the calculated angle.\n",
    "    return angle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classifyPose(landmarks, output_image):\n",
    "    # Initialize the label of the pose. It is not known at this stage.\n",
    "    label = 'Unknown Pose'\n",
    "\n",
    "    # Specify the color (Red) with which the label will be written on the image.\n",
    "    color = (0, 0, 255)\n",
    "\n",
    "    # Calculate the required angles.\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Get the angle between the left shoulder, elbow and wrist points.\n",
    "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "\n",
    "    # Get the angle between the right shoulder, elbow and wrist points.\n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "\n",
    "    # Get the angle between the left elbow, shoulder and hip points.\n",
    "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "\n",
    "    # Get the angle between the right hip, shoulder and elbow points.\n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "    # Get the angle between the left hip, knee and ankle points.\n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right hip, knee and ankle points\n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right shoulder, knee and hip points\n",
    "    right_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
    "\n",
    "    # Get the angle between the left shoulder, knee and hip points\n",
    "    left_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    angles = [round(left_elbow_angle, 2) / 360, round(right_elbow_angle, 2) / 360 ,\n",
    "              round(left_shoulder_angle, 2) / 360, round(right_shoulder_angle, 2) / 360, \n",
    "              round(left_hip_angle, 2) / 360, round(right_hip_angle, 2) / 360, round(left_knee_angle, 2) / 360, \n",
    "              round(right_knee_angle, 2) / 360]\n",
    "    feature_vector = np.array(angles).reshape(-1, 8)\n",
    "    prediction = model.predict(feature_vector)\n",
    "    \n",
    "    probable_act = np.argmax(prediction[0])\n",
    "    \n",
    "    if probable_act == 0:\n",
    "           label = 'Sitting'\n",
    "           \n",
    "    elif probable_act== 1:\n",
    "           label = 'Standing'\n",
    "           \n",
    "    elif probable_act== 2:\n",
    "           label = 'Walking'\n",
    "           \n",
    "    elif probable_act== 3:\n",
    "           label = 'Waving Hands'\n",
    "           \n",
    "    elif probable_act  == 4:\n",
    "           label = 'Yoga'\n",
    "           \n",
    "    elif probable_act == 5:\n",
    "           label = 'Squats'\n",
    "             \n",
    "    \n",
    "\n",
    "    # Check if the pose is classified successfully\n",
    "    if label != 'Unknown Pose':\n",
    "        # Update the color (to green) with which the label will be written on the image.\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "    # Write the label on the output image.\n",
    "    cv2.putText(output_image, label, (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "    \n",
    "    # print the pose details\n",
    "    # print(f\"{round(left_elbow_angle, 2)},{round(right_elbow_angle, 2)},{round(left_shoulder_angle, 2)},{round(right_shoulder_angle, 2)},{round(left_hip_angle, 2)},{round(right_hip_angle, 2)},{round(left_knee_angle, 2)},{round(right_knee_angle, 2)},Squats\")\n",
    "\n",
    "    return output_image, f'{label}'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        self.video_path = None\n",
    "        self.cap = None\n",
    "        self.playing = False\n",
    "\n",
    "        master.configure(background=\"skyblue\")\n",
    "\n",
    "        window_width = 900\n",
    "        window_height = 600\n",
    "\n",
    "        # get the screen width and height\n",
    "        screen_width = master.winfo_screenwidth()\n",
    "        screen_height = master.winfo_screenheight()\n",
    "\n",
    "        # calculate the x and y coordinates of the top-left corner of the window\n",
    "        x = (screen_width // 2) - (window_width // 2)\n",
    "        y = (screen_height // 2) - (window_height // 2)\n",
    "\n",
    "        root.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "\n",
    "        # create UI elements\n",
    "        self.label = tk.Label(master, text=\"No video selected\", font=(\"Arial\", 20), bg=\"skyblue\")\n",
    "        self.label.pack(pady=10)\n",
    "\n",
    "        self.button_select = tk.Button(master, text=\"Select video\", command=self.select_video, font=(\"Arial\", 20),\n",
    "                                       bg=\"yellow\")\n",
    "        self.button_select.pack()\n",
    "\n",
    "        self.button_play = tk.Button(master, text=\"Play\", state=\"disabled\", command=self.play_video, font=(\"Arial\", 20),\n",
    "                                     bg=\"white\")\n",
    "        self.button_play.pack(pady=10)\n",
    "\n",
    "        self.button_select = tk.Button(master, text=\"Use Camera\", command=self.webcam, font=(\"Arial\", 20),\n",
    "                                       bg=\"yellow\")\n",
    "        self.button_select.pack()\n",
    "\n",
    "    def select_video(self):\n",
    "        self.video_path = filedialog.askopenfilename()\n",
    "        self.label.config(text=self.video_path)\n",
    "        self.cap = cv2.VideoCapture(self.video_path)\n",
    "        self.button_play.config(state=\"normal\")\n",
    "\n",
    "    def select_cam(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "    def play_video(self):\n",
    "        if not self.playing:\n",
    "            self.playing = True\n",
    "            while True:\n",
    "                \n",
    "                ok, frame = self.cap.read()\n",
    "\n",
    "                if not ok:\n",
    "                    break\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "                frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "                frame, landmarks = detectPose(frame, pose_video)\n",
    "\n",
    "                if landmarks:\n",
    "                    \n",
    "                    frame, _ = classifyPose(landmarks, frame)\n",
    "\n",
    "                cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    self.label.configure(text=\"No Video Selected\")\n",
    "                    break\n",
    "                    \n",
    "            cv2.destroyAllWindows()\n",
    "            self.cap.release()\n",
    "            self.playing = False\n",
    "            self.button_play.config(text=\"Play\")\n",
    "        else:\n",
    "            self.playing = False\n",
    "\n",
    "    def webcam(self):\n",
    "        self.select_cam()\n",
    "        if not self.playing:\n",
    "            self.playing = True\n",
    "            while True:\n",
    "                ok, frame = self.cap.read()\n",
    "                \n",
    "\n",
    "                if not ok:\n",
    "                    break\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "                frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "                frame, landmarks = detectPose(frame, pose_video)\n",
    "\n",
    "                if landmarks:\n",
    "                    frame, _ = classifyPose(landmarks, frame)\n",
    "\n",
    "                cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    self.label.configure(text=\"No Video Selected\")\n",
    "                    break\n",
    "            \n",
    "            cv2.destroyAllWindows()\n",
    "            self.cap.release()\n",
    "            \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Human Activity Recognition App\")\n",
    "    player = VideoPlayer(root)\n",
    "    root.mainloop()\n",
    "    t1.join()\n",
    "    t3.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b443e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24c51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
