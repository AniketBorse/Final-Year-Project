{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c60218de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize the Face Detection module from Mediapipe\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "# Load the video or image you want to detect faces in\n",
    "cap = cv2.VideoCapture('Faces/2.mp4')\n",
    "\n",
    "# Initialize a counter variable for the number of faces detected\n",
    "face_count = 0\n",
    "\n",
    "# Iterate over the frames in the video or image\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Reset the face count at the start of each frame processing loop\n",
    "    face_count = 0\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run the face detection module on the RGB frame\n",
    "    results = mp_face_detection.FaceDetection().process(rgb_frame)\n",
    "\n",
    "    # Extract the faces detected in the frame and increment the counter\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            # Get the bounding box coordinates\n",
    "            bbox = detection.location_data.relative_bounding_box\n",
    "            x, y, w, h = int(bbox.xmin * frame.shape[1]), int(bbox.ymin * frame.shape[0]), \\\n",
    "                int(bbox.width * frame.shape[1]), int(bbox.height * frame.shape[0])\n",
    "\n",
    "            # Draw a bounding box around the face\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Increment the face counter\n",
    "            face_count += 1\n",
    "\n",
    "    # Display the resulting frame with the bounding boxes around the detected faces and the face count\n",
    "    cv2.putText(frame, f'Faces Detected: {face_count}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the OpenCV window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd413c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
